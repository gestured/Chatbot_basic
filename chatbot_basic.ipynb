{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A story and a question answer bot\n",
    "This chatbot takes a story and a question(yes/no) and answers according to the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocab in the model is limited to the dataset provided so this notebook only predicts a yes or no to a question of a story formed using the vocab in the train and test dataset combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and read the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt' , 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt' , 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = ' '.join(train_data[0][0])\n",
    "story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting train and test data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = train_data + test_data\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story,question,answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the data and splitting into train_story , train_query , train_answer and simillarly to test data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 1,\n",
       " 'moved': 2,\n",
       " 'left': 3,\n",
       " 'no': 4,\n",
       " 'down': 5,\n",
       " 'daniel': 6,\n",
       " 'yes': 7,\n",
       " 'dropped': 8,\n",
       " 'discarded': 9,\n",
       " 'put': 10,\n",
       " 'back': 11,\n",
       " 'bedroom': 12,\n",
       " 'football': 13,\n",
       " 'there': 14,\n",
       " 'picked': 15,\n",
       " 'got': 16,\n",
       " 'office': 17,\n",
       " 'garden': 18,\n",
       " 'is': 19,\n",
       " 'mary': 20,\n",
       " 'the': 21,\n",
       " 'to': 22,\n",
       " 'took': 23,\n",
       " 'journeyed': 24,\n",
       " 'milk': 25,\n",
       " 'bathroom': 26,\n",
       " 'grabbed': 27,\n",
       " 'john': 28,\n",
       " 'travelled': 29,\n",
       " 'went': 30,\n",
       " 'kitchen': 31,\n",
       " '?': 32,\n",
       " 'apple': 33,\n",
       " 'up': 34,\n",
       " 'hallway': 35,\n",
       " 'sandra': 36,\n",
       " '.': 37}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index , max_story_len = max_story_len, max_question_len=max_question_len):\n",
    "    X = [] #Stories\n",
    "    Xq = [] #Question\n",
    "    Y = [] #Answer\n",
    "    \n",
    "    for story,query,answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X , maxlen=max_story_len) , pad_sequences(Xq , maxlen=max_question_len) , np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train , query_train , answer_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test , query_test , answer_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input , Activation , Dense , Permute , Dropout , add , dot , concatenate , LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholders so to take two inputs story and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate keras tensor\n",
    "#Placeholder shape = (max_Story_len , batch_Size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "Reference : https://arxiv.org/pdf/1503.08895.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input encoder M\n",
    "\n",
    "input_encoder_m = Sequential()\n",
    "\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size , output_dim=64))\n",
    "\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#output\n",
    "#(Sample , story_maxlen , embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input encoder C\n",
    "\n",
    "input_encoder_c = Sequential()\n",
    "\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size , output_dim=max_question_len))\n",
    "\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#output\n",
    "#(Sample , story_maxlen , max_ques_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question encoder\n",
    "question_encoder = Sequential()\n",
    "\n",
    "question_encoder.add(Embedding(input_dim = vocab_size , output_dim = 64 , input_length=max_question_len))\n",
    "\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Output\n",
    "# (Samples , query max len , embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAssing placeholder in encoder\n",
    "\n",
    "#Encoded <----- Encoder(input)\n",
    "\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dot product\n",
    "\n",
    "match = dot([input_encoded_m , question_encoded] , axes=(2,2))\n",
    "\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add this matrix to second input vector seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match , input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response , question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)   # (samples , vocab_size) # yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence , question] , answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop' , loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.9528 - accuracy: 0.5009 - val_loss: 0.6983 - val_accuracy: 0.4970\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.7046 - accuracy: 0.5069 - val_loss: 0.6944 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6964 - accuracy: 0.5041 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6945 - accuracy: 0.5071 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6949 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6946 - accuracy: 0.5054 - val_loss: 0.6955 - val_accuracy: 0.5030\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6946 - accuracy: 0.5023 - val_loss: 0.6974 - val_accuracy: 0.4970\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6945 - accuracy: 0.5043 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6942 - accuracy: 0.5068 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6942 - accuracy: 0.5103 - val_loss: 0.6934 - val_accuracy: 0.4930\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6941 - accuracy: 0.5007 - val_loss: 0.6937 - val_accuracy: 0.4760\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6927 - accuracy: 0.5154 - val_loss: 0.6927 - val_accuracy: 0.4870\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6825 - accuracy: 0.5504 - val_loss: 0.6511 - val_accuracy: 0.6160\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.5680 - accuracy: 0.7269 - val_loss: 0.4848 - val_accuracy: 0.7630\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4645 - accuracy: 0.8047 - val_loss: 0.4442 - val_accuracy: 0.8210\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4233 - accuracy: 0.8286 - val_loss: 0.4042 - val_accuracy: 0.8200\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3979 - accuracy: 0.8360 - val_loss: 0.4001 - val_accuracy: 0.8290\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3765 - accuracy: 0.8455 - val_loss: 0.3977 - val_accuracy: 0.8400\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3649 - accuracy: 0.8498 - val_loss: 0.3906 - val_accuracy: 0.8470\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3532 - accuracy: 0.8524 - val_loss: 0.3750 - val_accuracy: 0.8370\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3501 - accuracy: 0.8537 - val_loss: 0.3637 - val_accuracy: 0.8480\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3422 - accuracy: 0.8559 - val_loss: 0.3648 - val_accuracy: 0.8420\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3370 - accuracy: 0.8604 - val_loss: 0.3501 - val_accuracy: 0.8450\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3294 - accuracy: 0.8606 - val_loss: 0.3541 - val_accuracy: 0.8400\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3256 - accuracy: 0.8625 - val_loss: 0.3507 - val_accuracy: 0.8380\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3218 - accuracy: 0.8620 - val_loss: 0.3729 - val_accuracy: 0.8220\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3194 - accuracy: 0.8629 - val_loss: 0.3464 - val_accuracy: 0.8330\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3192 - accuracy: 0.8609 - val_loss: 0.3668 - val_accuracy: 0.8400\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3154 - accuracy: 0.8617 - val_loss: 0.3546 - val_accuracy: 0.8420\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3126 - accuracy: 0.8658 - val_loss: 0.3490 - val_accuracy: 0.8320\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3082 - accuracy: 0.8638 - val_loss: 0.3433 - val_accuracy: 0.8430\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3056 - accuracy: 0.8652 - val_loss: 0.3507 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3101 - accuracy: 0.8628 - val_loss: 0.3650 - val_accuracy: 0.8420\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3028 - accuracy: 0.8684 - val_loss: 0.3437 - val_accuracy: 0.8360\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3051 - accuracy: 0.8668 - val_loss: 0.3494 - val_accuracy: 0.8240\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3021 - accuracy: 0.8659 - val_loss: 0.3522 - val_accuracy: 0.8390\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3018 - accuracy: 0.8688 - val_loss: 0.3486 - val_accuracy: 0.8390\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3001 - accuracy: 0.8692 - val_loss: 0.3484 - val_accuracy: 0.8350\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3003 - accuracy: 0.8683 - val_loss: 0.3501 - val_accuracy: 0.8320\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2960 - accuracy: 0.8671 - val_loss: 0.3405 - val_accuracy: 0.8380\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2972 - accuracy: 0.8671 - val_loss: 0.3500 - val_accuracy: 0.8360\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2950 - accuracy: 0.8704 - val_loss: 0.3454 - val_accuracy: 0.8390\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2944 - accuracy: 0.8705 - val_loss: 0.3567 - val_accuracy: 0.8330\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2928 - accuracy: 0.8723 - val_loss: 0.3685 - val_accuracy: 0.8360\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2918 - accuracy: 0.8699 - val_loss: 0.3538 - val_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2898 - accuracy: 0.8711 - val_loss: 0.3531 - val_accuracy: 0.8390\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2893 - accuracy: 0.8703 - val_loss: 0.3698 - val_accuracy: 0.8320\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2872 - accuracy: 0.8730 - val_loss: 0.3602 - val_accuracy: 0.8270\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2901 - accuracy: 0.8706 - val_loss: 0.3538 - val_accuracy: 0.8330\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2875 - accuracy: 0.8721 - val_loss: 0.3457 - val_accuracy: 0.8370\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2896 - accuracy: 0.8695 - val_loss: 0.3608 - val_accuracy: 0.8430\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2847 - accuracy: 0.8732 - val_loss: 0.3764 - val_accuracy: 0.8340\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2855 - accuracy: 0.8737 - val_loss: 0.3571 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2843 - accuracy: 0.8760 - val_loss: 0.3557 - val_accuracy: 0.8380\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2829 - accuracy: 0.8737 - val_loss: 0.3866 - val_accuracy: 0.8300\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2835 - accuracy: 0.8745 - val_loss: 0.3535 - val_accuracy: 0.8380\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2837 - accuracy: 0.8773 - val_loss: 0.3633 - val_accuracy: 0.8370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2846 - accuracy: 0.8732 - val_loss: 0.3747 - val_accuracy: 0.8370\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2818 - accuracy: 0.8772 - val_loss: 0.3550 - val_accuracy: 0.8380\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2772 - accuracy: 0.8770 - val_loss: 0.3634 - val_accuracy: 0.8320\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2806 - accuracy: 0.8776 - val_loss: 0.3812 - val_accuracy: 0.8330\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2790 - accuracy: 0.8772 - val_loss: 0.3863 - val_accuracy: 0.8390\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2737 - accuracy: 0.8786 - val_loss: 0.3691 - val_accuracy: 0.8410\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2761 - accuracy: 0.8760 - val_loss: 0.3820 - val_accuracy: 0.8300\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2766 - accuracy: 0.8769 - val_loss: 0.3721 - val_accuracy: 0.8430\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2739 - accuracy: 0.8793 - val_loss: 0.3779 - val_accuracy: 0.8370\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2739 - accuracy: 0.8798 - val_loss: 0.3911 - val_accuracy: 0.8410\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2727 - accuracy: 0.8755 - val_loss: 0.3702 - val_accuracy: 0.8340\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2681 - accuracy: 0.8844 - val_loss: 0.3719 - val_accuracy: 0.8300\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2698 - accuracy: 0.8804 - val_loss: 0.4098 - val_accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2692 - accuracy: 0.8832 - val_loss: 0.4106 - val_accuracy: 0.8330\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2697 - accuracy: 0.8812 - val_loss: 0.3735 - val_accuracy: 0.8370\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2651 - accuracy: 0.8814 - val_loss: 0.4156 - val_accuracy: 0.8340\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2633 - accuracy: 0.8815 - val_loss: 0.4204 - val_accuracy: 0.8270\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2671 - accuracy: 0.8843 - val_loss: 0.3724 - val_accuracy: 0.8420\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2609 - accuracy: 0.8832 - val_loss: 0.4162 - val_accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2588 - accuracy: 0.8847 - val_loss: 0.3954 - val_accuracy: 0.8320\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2614 - accuracy: 0.8865 - val_loss: 0.3977 - val_accuracy: 0.8440\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2596 - accuracy: 0.8826 - val_loss: 0.4069 - val_accuracy: 0.8390\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2598 - accuracy: 0.8862 - val_loss: 0.3829 - val_accuracy: 0.8380\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2566 - accuracy: 0.8842 - val_loss: 0.4452 - val_accuracy: 0.8350\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2561 - accuracy: 0.8897 - val_loss: 0.4087 - val_accuracy: 0.8370\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2528 - accuracy: 0.8892 - val_loss: 0.3939 - val_accuracy: 0.8390\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2572 - accuracy: 0.8889 - val_loss: 0.4268 - val_accuracy: 0.8360\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2496 - accuracy: 0.8897 - val_loss: 0.3947 - val_accuracy: 0.8410\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2447 - accuracy: 0.8933 - val_loss: 0.4246 - val_accuracy: 0.8360\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2512 - accuracy: 0.8878 - val_loss: 0.4345 - val_accuracy: 0.8350\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2473 - accuracy: 0.8886 - val_loss: 0.4569 - val_accuracy: 0.8350\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2473 - accuracy: 0.8901 - val_loss: 0.4282 - val_accuracy: 0.8400\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2413 - accuracy: 0.8947 - val_loss: 0.4373 - val_accuracy: 0.8440\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2384 - accuracy: 0.8973 - val_loss: 0.4504 - val_accuracy: 0.8340\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2434 - accuracy: 0.8933 - val_loss: 0.4552 - val_accuracy: 0.8320\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2386 - accuracy: 0.8956 - val_loss: 0.4260 - val_accuracy: 0.8410\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2390 - accuracy: 0.8959 - val_loss: 0.4777 - val_accuracy: 0.8400\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2331 - accuracy: 0.8964 - val_loss: 0.4515 - val_accuracy: 0.8410\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2363 - accuracy: 0.8960 - val_loss: 0.4497 - val_accuracy: 0.8490\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2305 - accuracy: 0.8985 - val_loss: 0.4504 - val_accuracy: 0.8460\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2317 - accuracy: 0.8961 - val_loss: 0.4445 - val_accuracy: 0.8420\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2373 - accuracy: 0.8962 - val_loss: 0.4356 - val_accuracy: 0.8360\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2334 - accuracy: 0.8998 - val_loss: 0.4375 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([input_train , query_train] , answer_train , batch_size=32 , epochs=100 , validation_data=([input_test , query_test] , answer_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "\n",
    "#summarize for history accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train' , 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Mychatbot_first.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting using the model on test_data without providing answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = model.predict(([input_test , query_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n",
      "Is John in the kitchen ?\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(test_data[0][0]))\n",
    "print(' '.join(test_data[0][1]))\n",
    "print(''.join(test_data[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16069165e-17, 8.48717004e-18, 1.06304852e-17, 8.70791477e-18,\n",
       "       9.99995947e-01, 7.56331683e-18, 6.77854991e-18, 4.03156309e-06,\n",
       "       1.02773154e-17, 6.32194373e-18, 8.62210719e-18, 8.98344284e-18,\n",
       "       9.44647704e-18, 7.61929380e-18, 9.58345815e-18, 9.37961603e-18,\n",
       "       9.31664029e-18, 6.60416907e-18, 8.83749013e-18, 7.96575343e-18,\n",
       "       1.10406385e-17, 8.10775718e-18, 1.05982135e-17, 1.05254498e-17,\n",
       "       1.08366790e-17, 8.30455586e-18, 7.66015156e-18, 9.78874205e-18,\n",
       "       1.01236162e-17, 9.49666292e-18, 8.46343989e-18, 7.69092516e-18,\n",
       "       8.29876063e-18, 9.11207604e-18, 1.03243101e-17, 7.60962075e-18,\n",
       "       7.70075951e-18, 7.91417211e-18], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer predicted :  no\n",
      "answer probability :  0.99999595\n"
     ]
    }
   ],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k=key\n",
    "print(\"answer predicted : \" , k)\n",
    "print(\"answer probability : \" , pred_res[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing our own stories\n",
    "#### Keeping in mind of our vocab we have to see that we use words that are in our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystory = \"John left the kitchen . Sandra dropped the football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystory.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ques = \"Is the football in the kitchen ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ques.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [(mystory.split() , my_ques.split() , 'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystory , my_ques , my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_my_res = model.predict([mystory , my_ques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer predicted :  no\n",
      "answer probability :  99.0454375743866 %\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(pred_my_res[0])\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k=key\n",
    "print(\"answer predicted : \" , k)\n",
    "print(\"answer probability : \" , pred_my_res[0][val_max]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That is the end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
